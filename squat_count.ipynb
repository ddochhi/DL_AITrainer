{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Install Package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mediapipe in /Users/gwon-yeonghyeon/anaconda3/envs/DL/lib/python3.10/site-packages (0.10.3)\n",
      "Requirement already satisfied: opencv-python in /Users/gwon-yeonghyeon/anaconda3/envs/DL/lib/python3.10/site-packages (4.8.0.76)\n",
      "Requirement already satisfied: absl-py in /Users/gwon-yeonghyeon/anaconda3/envs/DL/lib/python3.10/site-packages (from mediapipe) (1.4.0)\n",
      "Requirement already satisfied: attrs>=19.1.0 in /Users/gwon-yeonghyeon/anaconda3/envs/DL/lib/python3.10/site-packages (from mediapipe) (23.1.0)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in /Users/gwon-yeonghyeon/anaconda3/envs/DL/lib/python3.10/site-packages (from mediapipe) (23.5.26)\n",
      "Requirement already satisfied: matplotlib in /Users/gwon-yeonghyeon/anaconda3/envs/DL/lib/python3.10/site-packages (from mediapipe) (3.7.2)\n",
      "Requirement already satisfied: numpy in /Users/gwon-yeonghyeon/anaconda3/envs/DL/lib/python3.10/site-packages (from mediapipe) (1.25.2)\n",
      "Requirement already satisfied: opencv-contrib-python in /Users/gwon-yeonghyeon/anaconda3/envs/DL/lib/python3.10/site-packages (from mediapipe) (4.8.0.76)\n",
      "Requirement already satisfied: protobuf<4,>=3.11 in /Users/gwon-yeonghyeon/anaconda3/envs/DL/lib/python3.10/site-packages (from mediapipe) (3.20.3)\n",
      "Requirement already satisfied: sounddevice>=0.4.4 in /Users/gwon-yeonghyeon/anaconda3/envs/DL/lib/python3.10/site-packages (from mediapipe) (0.4.6)\n",
      "Requirement already satisfied: CFFI>=1.0 in /Users/gwon-yeonghyeon/anaconda3/envs/DL/lib/python3.10/site-packages (from sounddevice>=0.4.4->mediapipe) (1.15.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/gwon-yeonghyeon/anaconda3/envs/DL/lib/python3.10/site-packages (from matplotlib->mediapipe) (1.1.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/gwon-yeonghyeon/anaconda3/envs/DL/lib/python3.10/site-packages (from matplotlib->mediapipe) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/gwon-yeonghyeon/anaconda3/envs/DL/lib/python3.10/site-packages (from matplotlib->mediapipe) (4.42.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/gwon-yeonghyeon/anaconda3/envs/DL/lib/python3.10/site-packages (from matplotlib->mediapipe) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/gwon-yeonghyeon/anaconda3/envs/DL/lib/python3.10/site-packages (from matplotlib->mediapipe) (23.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /Users/gwon-yeonghyeon/anaconda3/envs/DL/lib/python3.10/site-packages (from matplotlib->mediapipe) (10.0.0)\n",
      "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in /Users/gwon-yeonghyeon/anaconda3/envs/DL/lib/python3.10/site-packages (from matplotlib->mediapipe) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/gwon-yeonghyeon/anaconda3/envs/DL/lib/python3.10/site-packages (from matplotlib->mediapipe) (2.8.2)\n",
      "Requirement already satisfied: pycparser in /Users/gwon-yeonghyeon/anaconda3/envs/DL/lib/python3.10/site-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe) (2.21)\n",
      "Requirement already satisfied: six>=1.5 in /Users/gwon-yeonghyeon/anaconda3/envs/DL/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib->mediapipe) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install mediapipe opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install mediapipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Import Package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 # openCV 라이브러리 \n",
    "import mediapipe as mp\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Calculate Angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2차원\n",
    "def calculate_angle(a,b,c):\n",
    "    a = np.array(a) # First\n",
    "    b = np.array(b) # Mid\n",
    "    c = np.array(c) # End\n",
    "    \n",
    "    radians = np.arctan2(c[1]-b[1], c[0]-b[0]) - np.arctan2(a[1]-b[1], a[0]-b[0])\n",
    "    angle = np.abs(radians*180.0/np.pi)\n",
    "    \n",
    "    if angle >180.0:\n",
    "        angle = 360-angle # 다리는 180도가 최대\n",
    "        \n",
    "    return angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 3차원\n",
    "# def calculate_angle(a, b, c):\n",
    "    \n",
    "#     a = np.array(a) # First\n",
    "#     b = np.array(b) # Mid\n",
    "#     c = np.array(c) # End\n",
    "\n",
    "#     # AB 벡터와 BC 벡터를 계산합니다.\n",
    "#     AB = np.array([b[0] - a[0], b[1] - a[1], b[2] - a[2]])\n",
    "#     BC = np.array([c[0] - b[0], c[1] - b[1], c[2] - b[2]])\n",
    "\n",
    "#     # AB 벡터와 BC 벡터의 내적을 계산합니다.\n",
    "#     dot_product = np.dot(AB, BC)\n",
    "\n",
    "#     # AB 벡터와 BC 벡터의 크기를 계산합니다.\n",
    "#     norm_AB = np.linalg.norm(AB)\n",
    "#     norm_BC = np.linalg.norm(BC)\n",
    "\n",
    "#     # 각을 라디안 단위로 계산합니다.\n",
    "#     cosine_theta = dot_product / (norm_AB * norm_BC)\n",
    "#     angle_radians = np.arccos(cosine_theta)\n",
    "\n",
    "#     # 라디안에서 도로 변환합니다.\n",
    "#     angle = 360 - np.degrees(angle_radians) - 180\n",
    "\n",
    "\n",
    "#     return angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m현재 셀 또는 이전 셀에서 코드를 실행하는 동안 Kernel이 충돌했습니다. 셀의 코드를 검토하여 오류의 가능한 원인을 식별하세요. 자세한 내용을 보려면 <a href='https://aka.ms/vscodeJupyterKernelCrash'> 여기 </a> 를 클릭하세요. 자세한 내용은 Jupyter <a href='command:jupyter.viewOutput'>로그</a>를 참조하세요."
     ]
    }
   ],
   "source": [
    "# mp_drawing = mp.solutions.drawing_utils\n",
    "# mp_pose = mp.solutions.pose\n",
    "\n",
    "# cap = cv2.VideoCapture(\"/Users/gwon-yeonghyeon/Desktop/DL project/mp4/squat.mp4\")\n",
    "\n",
    "# count = 0\n",
    "# stage = None\n",
    "\n",
    "# ## Setup mediapipe instance\n",
    "# with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
    "#     while cap.isOpened():\n",
    "#         ret, frame = cap.read()\n",
    "        \n",
    "#         # 프레임이 비어있는 경우 무시하고 다음 프레임으로 진행\n",
    "#         if not ret:\n",
    "#             continue\n",
    "        \n",
    "#         # Recolor image to RGB\n",
    "#         image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "#         image.flags.writeable = False\n",
    "      \n",
    "#         # Make detection\n",
    "#         results = pose.process(image)\n",
    "    \n",
    "#         # Recolor back to BGR\n",
    "#         image.flags.writeable = True\n",
    "#         image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "#         # Extract landmarks\n",
    "#         try:\n",
    "#             landmarks = results.pose_landmarks.landmark\n",
    "            \n",
    "#             # Get coordinates\n",
    "#             shoulder = [landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].x,landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].y]\n",
    "#             hip = [landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].x,landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].y]\n",
    "#             knee = [landmarks[mp_pose.PoseLandmark.LEFT_KNEE.value].x,landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].y]\n",
    "#             ankle = [landmarks[mp_pose.PoseLandmark.LEFT_ANKLE.value].x,landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].y]\n",
    "            \n",
    "#             # 어깨, 팔꿈치, 손목 간의 각도 계산\n",
    "#             # angle = calculate_angle(hip, knee, ankle)\n",
    "            \n",
    "#             angle_knee = calculate_angle(hip, knee, ankle)\n",
    "#             knee_angle = 180-angle_knee\n",
    "\n",
    "#             angle_hip = calculate_angle(shoulder, hip, knee)\n",
    "#             hip_angle = 180-angle_hip\n",
    "\n",
    "\n",
    "#             # 이미지에 계산된 각도 시각화\n",
    "#             cv2.putText(image, str(knee_angle), \n",
    "#                            tuple(np.multiply(knee, [640, 480]).astype(int)), \n",
    "#                            cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2, cv2.LINE_AA\n",
    "#                                 )\n",
    "            \n",
    "#             if knee_angle > 100:\n",
    "#                 stage = \"up\"\n",
    "#             if knee_angle < 30 and stage =='up':\n",
    "#                 stage=\"down\"\n",
    "#                 count += 1\n",
    "                       \n",
    "#         except:\n",
    "#             pass\n",
    "        \n",
    "#         # Render curl counter\n",
    "#         # angle 표시\n",
    "#         cv2.rectangle(image, (0,0), (225,73), (245,117,16), -1)      \n",
    "        \n",
    "#         cv2.putText(image, str(knee_angle), \n",
    "#                     (10,60), \n",
    "#                     cv2.FONT_HERSHEY_SIMPLEX, 2, (255,255,255), 2, cv2.LINE_AA)  \n",
    "        \n",
    "#         cv2.putText(image, stage, \n",
    "#                     (60,60), \n",
    "#                     cv2.FONT_HERSHEY_SIMPLEX, 2, (255,255,255), 2, cv2.LINE_AA)  \n",
    "        \n",
    "#         # 검출된 포즈 랜드마크를 이미지에 시각화\n",
    "#         mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS,\n",
    "#                                 mp_drawing.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=2), \n",
    "#                                 mp_drawing.DrawingSpec(color=(245,66,230), thickness=2, circle_radius=2) \n",
    "#                                  )               \n",
    "        \n",
    "#         # 렌더링된 이미지를 Mediapipe Feed라는 창에 표시\n",
    "#         cv2.imshow('Mediapipe Feed', image)\n",
    "\n",
    "#         # 'q' 키를 누르면 루프 종료\n",
    "#         if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "#             break\n",
    "\n",
    "#     cap.release()\n",
    "#     cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OpenCV: FFMPEG: tag 0x5634504d/'MP4V' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "87.31  _  176.41\n",
      "83.01  _  171.92\n",
      "2\n",
      "67.31  _  178.24\n",
      "61.97  _  174.94\n",
      "3\n",
      "70.95  _  177.12\n",
      "66.99  _  175.07\n",
      "4\n",
      "74.48  _  179.74\n",
      "68.36  _  175.75\n",
      "5\n",
      "65.45  _  178.73\n",
      "60.18  _  175.27\n",
      "6\n",
      "61.09  _  180.0\n",
      "53.77  _  175.8\n",
      "7\n",
      "70.03  _  178.58\n",
      "64.14  _  175.05\n",
      "8\n",
      "71.45  _  179.38\n",
      "63.78  _  175.72\n",
      "9\n",
      "64.27  _  179.07\n",
      "59.07  _  175.61\n",
      "10\n",
      "62.94  _  179.31\n",
      "57.33  _  176.02\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 28\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[39mwith\u001b[39;00m mp_pose\u001b[39m.\u001b[39mPose(min_detection_confidence\u001b[39m=\u001b[39m\u001b[39m0.5\u001b[39m, min_tracking_confidence\u001b[39m=\u001b[39m\u001b[39m0.5\u001b[39m) \u001b[39mas\u001b[39;00m pose:\n\u001b[1;32m     27\u001b[0m     \u001b[39mwhile\u001b[39;00m cap\u001b[39m.\u001b[39misOpened():\n\u001b[0;32m---> 28\u001b[0m         ret, frame \u001b[39m=\u001b[39m cap\u001b[39m.\u001b[39;49mread()\n\u001b[1;32m     29\u001b[0m         \u001b[39m# if frame is not None:\u001b[39;00m\n\u001b[1;32m     30\u001b[0m         \u001b[39m#     frame_ = rescale_frame(frame, percent=75)\u001b[39;00m\n\u001b[1;32m     31\u001b[0m         \n\u001b[1;32m     32\u001b[0m         \u001b[39m# 프레임이 비어있는 경우 무시하고 다음 프레임으로 진행\u001b[39;00m\n\u001b[1;32m     33\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m ret:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "angle_min = []\n",
    "angle_min_hip = []\n",
    "\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_pose = mp.solutions.pose\n",
    "\n",
    "cap = cv2.VideoCapture(\"/Users/gwon-yeonghyeon/Desktop/DL project/mp4/squat.mp4\")\n",
    "\n",
    "# Curl counter variables\n",
    "counter = 0 \n",
    "min_ang = 0\n",
    "max_ang = 0\n",
    "min_ang_hip = 0\n",
    "max_ang_hip = 0\n",
    "stage = None\n",
    "\n",
    "# width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH) + 0.5)\n",
    "# height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT) + 0.5)\n",
    "# size = (640, 480)\n",
    "# fourcc = cv2.VideoWriter_fourcc(*'MP4V')\n",
    "# out = cv2.VideoWriter('output_video_.mp4', fourcc, 24, size)\n",
    "\n",
    "with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        # 프레임이 비어있는 경우 무시하고 다음 프레임으로 진행\n",
    "        if not ret:\n",
    "            continue\n",
    "\n",
    "        # Recolor image to RGB\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        image.flags.writeable = False\n",
    "      \n",
    "        # Make detection\n",
    "        results = pose.process(image)\n",
    "    \n",
    "        # Recolor back to BGR\n",
    "        image.flags.writeable = True\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "        # Extract landmarks\n",
    "        try:\n",
    "            landmarks = results.pose_landmarks.landmark\n",
    "            \n",
    "            # Get coordinates\n",
    "            shoulder = [landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].x,landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].y]\n",
    "            hip = [landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value].x,landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value].y]\n",
    "            knee = [landmarks[mp_pose.PoseLandmark.RIGHT_KNEE.value].x,landmarks[mp_pose.PoseLandmark.RIGHT_KNEE.value].y]\n",
    "            ankle = [landmarks[mp_pose.PoseLandmark.RIGHT_ANKLE.value].x,landmarks[mp_pose.PoseLandmark.RIGHT_ANKLE.value].y]\n",
    "            \n",
    "            \n",
    "            angle_knee = calculate_angle(hip, knee, ankle) #Knee joint angle\n",
    "            angle_knee = round(angle_knee,2)\n",
    "            \n",
    "            angle_hip = calculate_angle(shoulder, hip, knee)\n",
    "            angle_hip = round(angle_hip,2)\n",
    "            \n",
    "            hip_angle = 180-angle_hip\n",
    "            knee_angle = 180-angle_knee\n",
    "            \n",
    "            \n",
    "            angle_min.append(angle_knee)\n",
    "            angle_min_hip.append(angle_hip)\n",
    "            \n",
    "            cv2.putText(image, str(angle_knee), \n",
    "                           tuple(np.multiply(knee, [1500, 800]).astype(int)), \n",
    "                           cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255,255,255), 2, cv2.LINE_AA\n",
    "                                )\n",
    "            \n",
    "            cv2.putText(image, str(angle_hip), \n",
    "                           tuple(np.multiply(hip, [1500, 800]).astype(int)), \n",
    "                           cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2, cv2.LINE_AA\n",
    "                                )\n",
    "            \n",
    "            # Curl counter logic\n",
    "            if angle_knee > 169:\n",
    "                stage = \"up\"\n",
    "            if angle_knee <= 90 and stage =='up':\n",
    "                stage=\"down\"\n",
    "                counter +=1\n",
    "                print(counter)\n",
    "                min_ang  =min(angle_min)\n",
    "                max_ang = max(angle_min)\n",
    "                \n",
    "                min_ang_hip  =min(angle_min_hip)\n",
    "                max_ang_hip = max(angle_min_hip)\n",
    "                \n",
    "                print(min(angle_min), \" _ \", max(angle_min))\n",
    "                print(min(angle_min_hip), \" _ \", max(angle_min_hip))\n",
    "                angle_min = []\n",
    "                angle_min_hip = []\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        # Render squat counter\n",
    "        # Setup status box\n",
    "        cv2.rectangle(image, (20,20), (435,160), (0,0,0), -1)\n",
    "        \n",
    "        # Rep data\n",
    "        cv2.putText(image, \"Repetition : \" + str(counter), \n",
    "                    (30,60), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,255), 2, cv2.LINE_AA)\n",
    " \n",
    "        cv2.putText(image, \"Knee-joint angle : \" + str(min_ang), \n",
    "                    (30,100), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,255), 2, cv2.LINE_AA)\n",
    "        \n",
    "        #Hip angle:\n",
    "        cv2.putText(image, \"Hip-joint angle : \" + str(min_ang_hip), \n",
    "                    (30,140), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,255), 2, cv2.LINE_AA)\n",
    "        \n",
    "\n",
    "        \n",
    "        \n",
    "        # Render detections\n",
    "        mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS,\n",
    "                                mp_drawing.DrawingSpec(color=(0,0,0), thickness=2, circle_radius=2), \n",
    "                                mp_drawing.DrawingSpec(color=(203,17,17), thickness=2, circle_radius=2) \n",
    "                                 )               \n",
    "        \n",
    "        # out.write(image)\n",
    "        cv2.imshow('Mediapipe Feed', image)\n",
    "\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            cap.release()\n",
    "            # out.release()\n",
    "            cv2.destroyAllWindows()\n",
    "            #break\n",
    "\n",
    "    cap.release()\n",
    "    # out.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
